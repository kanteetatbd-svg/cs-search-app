import streamlit as st
import pandas as pd
from google.cloud import bigquery
from google.oauth2 import service_account

st.set_page_config(page_title="CS Final Search", layout="wide")
st.title("üöÄ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (‡πÄ‡∏ß‡∏≠‡∏£‡πå‡∏ä‡∏±‡∏ô‡∏Å‡∏ß‡∏≤‡∏î‡∏ó‡∏∏‡∏Å‡πÅ‡∏ó‡πá‡∏ö)")

@st.cache_resource
def get_bq_client():
    try:
        scopes = ["https://www.googleapis.com/auth/cloud-platform", "https://www.googleapis.com/auth/drive"]
        creds = service_account.Credentials.from_service_account_file('key.json', scopes=scopes)
        return bigquery.Client(credentials=creds, project=creds.project_id)
    except Exception as e:
        st.error(f"‚ùå ‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {e}")
        return None

client = get_bq_client()
search_id = st.text_input("üîç ‡∏Å‡∏£‡∏≠‡∏Å ID ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô:")

if client and search_id:
    PROJECT_ID = "sturdy-sentry-487204-s4"
    DATASET_ID = "cs_database"
    search_val = search_id.strip()
    
    try:
        tables = client.list_tables(f"{PROJECT_ID}.{DATASET_ID}")
        found_data = {}

        for table in tables:
            full_table_id = f"{PROJECT_ID}.{DATASET_ID}.{table.table_id}"
            # ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏≤‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÑ‡∏°‡πà‡∏à‡∏≥‡∏Å‡∏±‡∏î‡πÅ‡∏ñ‡∏ß) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏°‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏ô‡∏´‡∏≤‡πÉ‡∏ô Python ‡πÅ‡∏ó‡∏ô
            df_all = client.query(f"SELECT * FROM `{full_table_id}`").to_dataframe()
            
            if not df_all.empty:
                # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ID ‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡∏™‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ß‡πà‡∏≤‡∏á
                mask = df_all.astype(str).apply(lambda x: x.str.contains(search_val, case=False, na=False)).any(axis=1)
                result_df = df_all[mask]
                
                if not result_df.empty:
                    found_data[table.table_id] = result_df

        if found_data:
            st.success(f"‚úÖ ‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• ID `{search_val}` ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á‡∏Ñ‡∏£‡∏±‡∏ö!")
            tabs = st.tabs(list(found_data.keys()))
            for i, (name, df) in enumerate(found_data.items()):
                with tabs[i]:
                    st.write(f"üìÇ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÅ‡∏ó‡πá‡∏ö: **{name}**")
                    st.dataframe(df, use_container_width=True)
        else:
            st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö ID `{search_val}` ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á)")
            # ‡πÇ‡∏ä‡∏ß‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• 50 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏µ‡πà‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡∏°‡∏±‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ó‡∏µ‡πà‡πÅ‡∏ñ‡∏ß‡πÑ‡∏´‡∏ô
            first_table = list(client.list_tables(f"{PROJECT_ID}.{DATASET_ID}"))[0].table_id
            debug_df = client.query(f"SELECT * FROM `{PROJECT_ID}.{DATASET_ID}.{first_table}` LIMIT 50").to_dataframe()
            st.info(f"üí° ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏î‡∏¥‡∏ö 50 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å‡∏Ç‡∏≠‡∏á {first_table}:")
            st.dataframe(debug_df)

    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
