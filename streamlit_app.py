import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials

st.set_page_config(page_title="CS Case Finder LIGHTNING", layout="wide")
st.title("‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏Ñ‡∏™ CS")

# --- 1. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets ---
@st.cache_resource
def get_sheets_client():
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        creds = Credentials.from_service_account_file('key.json', scopes=scopes)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"‚ùå ‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {e}")
        return None

# --- 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• + ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥ ---
@st.cache_data(ttl=900) # ‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ß‡πâ 15 ‡∏ô‡∏≤‡∏ó‡∏µ
def load_all_data_fast():
    gc = get_sheets_client()
    if not gc: return {}
    
    sh = gc.open('Copy of ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏Ñ‡∏™2025V1')
    worksheets = sh.worksheets()
    
    ranges = [f"'{ws.title}'" for ws in worksheets]
    all_data = {}
    
    try:
        batch_result = sh.values_batch_get(ranges)
        value_ranges = batch_result.get('valueRanges', [])
        
        for ws, val_range in zip(worksheets, value_ranges):
            values = val_range.get('values', [])
            if not values: continue
            
            df = pd.DataFrame(values)
            
            # üéØ ‡πÑ‡∏°‡πâ‡∏ï‡∏≤‡∏¢: ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡πâ‡∏à‡∏£‡∏¥‡∏á
            # ‡∏™‡πÅ‡∏Å‡∏ô 20 ‡πÅ‡∏ñ‡∏ß‡πÅ‡∏£‡∏Å ‡∏´‡∏≤‡πÅ‡∏ñ‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏¢‡∏≠‡∏∞‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î (‡∏ô‡∏±‡πà‡∏ô‡πÅ‡∏´‡∏•‡∏∞‡∏Ñ‡∏∑‡∏≠‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡∏≠‡∏á‡∏û‡∏µ‡πà)
            header_idx = 0
            max_non_empty = 0
            
            for idx in range(min(20, len(df))):
                # ‡∏ô‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡πà‡∏≠‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ï‡∏±‡∏ß‡∏´‡∏ô‡∏±‡∏á‡∏™‡∏∑‡∏≠‡πÉ‡∏ô‡πÅ‡∏ñ‡∏ß‡∏ô‡∏±‡πâ‡∏ô
                count = sum(1 for x in df.iloc[idx] if str(x).strip() not in ['', 'None', 'nan'])
                if count > max_non_empty:
                    max_non_empty = count
                    header_idx = idx
            
            # ‡∏î‡∏∂‡∏á‡πÅ‡∏ñ‡∏ß‡∏ô‡∏±‡πâ‡∏ô‡∏°‡∏≤‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            raw_headers = df.iloc[header_idx].astype(str).tolist()
            
            # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ã‡πâ‡∏≥‡∏´‡∏£‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡∏á‡πÄ‡∏õ‡∏•‡πà‡∏≤ ‡πÉ‡∏´‡πâ‡∏£‡∏∞‡∏ö‡∏ö‡πÑ‡∏°‡πà Error
            final_headers = []
            for col_idx, h in enumerate(raw_headers):
                clean_h = h.strip()
                if not clean_h or clean_h in ['None', 'nan']:
                    clean_h = f"‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå_{col_idx}"
                if clean_h in final_headers:
                    clean_h = f"{clean_h}_{col_idx}"
                final_headers.append(clean_h)
            
            df.columns = final_headers
            
            # ‡∏ï‡∏±‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô Dashboard ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏ó‡∏¥‡πâ‡∏á‡πÑ‡∏õ ‡πÄ‡∏≠‡∏≤‡πÅ‡∏ï‡πà‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏£‡∏¥‡∏á‡πÜ
            df = df.iloc[header_idx + 1 :].reset_index(drop=True)
            
            all_data[ws.title] = df
            
        return all_data
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        return {}

# --- 3. ‡∏™‡πà‡∏ß‡∏ô‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏´‡∏•‡∏±‡∏Å ---
if st.sidebar.button("üîÑ ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡∏à‡∏≤‡∏Å Sheets"):
    st.cache_data.clear()
    st.rerun()

with st.spinner('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î...'):
    master_data = load_all_data_fast()

search_val = st.text_input("üîç ‡∏Å‡∏£‡∏≠‡∏Å ID ‡∏´‡∏£‡∏∑‡∏≠ IMEI ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Enter:")

if search_val:
    q = search_val.strip().lower()
    found_results = {}

    for title, df in master_data.items():
        if df.empty: continue
        
        # ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÅ‡∏ö‡∏ö‡∏Å‡∏ß‡∏≤‡∏î‡∏£‡∏ß‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏ó‡∏±‡πâ‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á
        combined_text = df.astype(str).agg(' '.join, axis=1).str.lower()
        mask = combined_text.str.contains(q, na=False)
        res = df[mask]
        
        if not res.empty:
            found_results[title] = res

    # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•
    if found_results:
        st.success(f"‚úÖ ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô `{search_val}` ‡πÉ‡∏ô {len(found_results)} ‡πÅ‡∏ó‡πá‡∏ö")
        for name, res_df in found_results.items():
            st.markdown(f"### üìÇ ‡πÅ‡∏ó‡πá‡∏ö: {name}")
            # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏à‡∏£‡∏¥‡∏á‡πÜ ‡πÅ‡∏•‡πâ‡∏ß
            st.dataframe(res_df, use_container_width=True, hide_index=True)
            st.divider()
    else:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• `{search_val}`")
