import streamlit as st
import pandas as pd
from google.cloud import bigquery
from google.oauth2 import service_account

st.set_page_config(page_title="BigQuery Multi-Search", layout="wide")
st.title("üöÄ ‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ID ‡∏ó‡∏∏‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô BigQuery")

# --- 1. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠‡∏Å‡∏∏‡∏ç‡πÅ‡∏à (‡πÉ‡∏ä‡πâ Scopes ‡πÉ‡∏´‡πâ‡∏Ñ‡∏£‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡πà‡∏≤‡∏ô Sheets ‡∏ó‡∏µ‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏Å‡∏±‡∏ö BigQuery) ---
@st.cache_resource
def get_bq_client():
    try:
        scopes = [
            "https://www.googleapis.com/auth/cloud-platform",
            "https://www.googleapis.com/auth/drive",
            "https://www.googleapis.com/auth/bigquery"
        ]
        creds = service_account.Credentials.from_service_account_file('key.json', scopes=scopes)
        return bigquery.Client(credentials=creds, project=creds.project_id)
    except Exception as e:
        st.error(f"‚ùå ‡∏Å‡∏∏‡∏ç‡πÅ‡∏à‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤: {e}")
        return None

client = get_bq_client()

# --- 2. ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ ---
search_id = st.text_input("üîç ‡∏Å‡∏£‡∏≠‡∏Å ID ‡∏û‡∏ô‡∏±‡∏Å‡∏á‡∏≤‡∏ô‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á:", placeholder="‡πÄ‡∏ä‡πà‡∏ô 9300191")

if client and search_id:
    # ‡∏£‡∏∞‡∏ö‡∏∏‡∏ä‡∏∑‡πà‡∏≠‡πÇ‡∏õ‡∏£‡πÄ‡∏à‡∏Å‡∏ï‡πå‡πÅ‡∏•‡∏∞ Dataset
    project_id = "sturdy-sentry-487204-s4"
    dataset_id = "cs_database"
    
    try:
        # ‡∏î‡∏∂‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÉ‡∏ô Dataset ‡∏ô‡∏µ‡πâ (‡πÅ‡∏ó‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏õ‡∏¥‡∏î‡∏î‡∏π‡∏ó‡∏∏‡∏Å‡πÅ‡∏ó‡πá‡∏ö)
        tables = client.list_tables(f"{project_id}.{dataset_id}")
        
        found_any = False
        st.markdown(f"### üîé ‡∏ú‡∏•‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö ID: `{search_id}`")

        for table in tables:
            full_table_id = f"{project_id}.{dataset_id}.{table.table_id}"
            
            # ‡∏î‡∏∂‡∏á‡∏´‡∏±‡∏ß‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏°‡∏≤‡πÄ‡∏ä‡πá‡∏Å‡∏Å‡πà‡∏≠‡∏ô 1 ‡πÅ‡∏ñ‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏´‡∏≤‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå
            check_df = client.query(f"SELECT * FROM `{full_table_id}` LIMIT 1").to_dataframe()
            cols = check_df.columns.tolist()
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á SQL ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ (‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÉ‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ ‡πÄ‡∏ú‡∏∑‡πà‡∏≠ ID ‡∏≠‡∏¢‡∏π‡πà‡∏Ñ‡∏ô‡∏•‡∏∞‡∏ó‡∏µ‡πà)
            # ‡πÄ‡∏£‡∏≤‡∏à‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á WHERE col1='ID' OR col2='ID' ...
            where_clause = " OR ".join([f"CAST({col} AS STRING) = '{search_id}'" for col in cols])
            sql = f"SELECT * FROM `{full_table_id}` WHERE {where_clause}"
            
            try:
                result_df = client.query(sql).to_dataframe()
                
                if not result_df.empty:
                    found_any = True
                    # ‡πÅ‡∏¢‡∏Å‡πÇ‡∏ä‡∏ß‡πå‡∏ï‡∏≤‡∏°‡∏ä‡∏∑‡πà‡∏≠‡∏ï‡∏≤‡∏£‡∏≤‡∏á (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÅ‡∏¢‡∏Å‡∏ï‡∏≤‡∏°‡πÅ‡∏ó‡πá‡∏ö)
                    with st.expander(f"‚úÖ ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á: {table.table_id}", expanded=True):
                        st.dataframe(result_df, use_container_width=True)
            except:
                continue # ‡∏Ç‡πâ‡∏≤‡∏°‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏õ‡∏±‡∏ç‡∏´‡∏≤‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á

        if not found_any:
            st.warning(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö ID '{search_id}' ‡πÉ‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏î‡πÜ ‡πÄ‡∏•‡∏¢")

    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
else:
    st.info("üí° ‡πÉ‡∏™‡πà ID ‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏Ñ‡∏ß‡∏≤‡∏ô‡∏´‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏Å‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÉ‡∏ô BigQuery ‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡∏Ñ‡∏£‡∏±‡∏ö")
