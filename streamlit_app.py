Big Query Code
import streamlit as st
import pandas as pd
import gspread
from google.oauth2.service_account import Credentials

st.set_page_config(page_title="CS Case Finder LIGHTNING", layout="wide")
st.title("‡∏£‡∏∞‡∏ö‡∏ö‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡πÄ‡∏Ñ‡∏™ CS")

# --- 1. ‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‡∏ï‡πà‡∏≠ Google Sheets ---
@st.cache_resource
def get_sheets_client():
    try:
        scopes = ['https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive']
        creds = Credentials.from_service_account_file('key.json', scopes=scopes)
        return gspread.authorize(creds)
    except Exception as e:
        st.error(f"‚ùå KeyError: {e}")
        return None

# --- 2. ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• "‡∏ó‡∏∏‡∏Å‡πÅ‡∏ó‡πá‡∏ö" ‡πÉ‡∏ô‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (API Call ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß) ---
@st.cache_data(ttl=900) # ‡∏à‡∏≥‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏ß‡πâ 15 ‡∏ô‡∏≤‡∏ó‡∏µ
def load_all_data_fast():
    gc = get_sheets_client()
    if not gc: return {}
    
    sh = gc.open('Copy of ‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏Å‡πá‡∏ö‡πÄ‡∏Ñ‡∏™2025V1')
    worksheets = sh.worksheets()
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ó‡πá‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡πà‡∏á‡πÑ‡∏õ‡∏Ç‡∏≠ Google ‡∏ó‡∏µ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß
    ranges = [f"'{ws.title}'" for ws in worksheets]
    all_data = {}
    
    try:
        # ‚ö° ‡πÑ‡∏°‡πâ‡∏ï‡∏≤‡∏¢‡∏ó‡∏µ‡πà 1: ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏∏‡∏Å‡πÅ‡∏ó‡πá‡∏ö‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô‡πÉ‡∏ô 1 ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á (‡∏Ç‡πâ‡∏≤‡∏°‡∏Ñ‡∏≠‡∏Ç‡∏ß‡∏î‡πÄ‡∏ô‡πá‡∏ï)
        batch_result = sh.values_batch_get(ranges)
        value_ranges = batch_result.get('valueRanges', [])
        
        # ‡∏à‡∏±‡∏ö‡∏Ñ‡∏π‡πà‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏ó‡πá‡∏ö‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏°‡∏≤
        for ws, val_range in zip(worksheets, value_ranges):
            values = val_range.get('values', [])
            if values:
                all_data[ws.title] = pd.DataFrame(values)
        return all_data
    except Exception as e:
        st.error(f"‡πÄ‡∏Å‡∏¥‡∏î‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {e}")
        return {}

# --- 3. ‡∏™‡πà‡∏ß‡∏ô‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏´‡∏•‡∏±‡∏Å ---
# ‡∏õ‡∏∏‡πà‡∏°‡∏£‡∏µ‡πÄ‡∏ü‡∏£‡∏ä ‡πÄ‡∏ú‡∏∑‡πà‡∏≠‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡∏ô‡∏ó‡∏µ
if st.sidebar.button("üîÑ ‡∏≠‡∏±‡∏û‡πÄ‡∏î‡∏ó‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"):
    st.cache_data.clear()
    st.rerun()

# ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏£‡∏≠‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡πÅ‡∏£‡∏°‡πÄ‡∏•‡∏¢ (‡∏£‡∏≠‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏Ñ‡πà‡∏ï‡∏≠‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÅ‡∏≠‡∏õ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å)
with st.spinner('‚ö° ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏î‡∏π‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡πÑ‡∏ß‡πâ‡πÉ‡∏ô‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á (‡∏£‡∏≠‡πÅ‡∏Ñ‡πà‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡πÅ‡∏£‡∏Å)...'):
    master_data = load_all_data_fast()

search_val = st.text_input("üîç ‡∏Å‡∏£‡∏≠‡∏Å ID ‡∏´‡∏£‡∏∑‡∏≠ IMEI ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Enter")

if search_val:
    q = search_val.strip().lower()
    found_results = {}

    for title, df in master_data.items():
        if df.empty: continue
        
        # ‚ö° ‡πÑ‡∏°‡πâ‡∏ï‡∏≤‡∏¢‡∏ó‡∏µ‡πà 2: ‡∏£‡∏ß‡∏ö‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏î‡∏µ‡∏¢‡∏ß ‡πÅ‡∏•‡πâ‡∏ß‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏£‡∏ß‡∏î‡πÄ‡∏î‡∏µ‡∏¢‡∏ß (‡πÄ‡∏£‡πá‡∏ß‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏° 100 ‡πÄ‡∏ó‡πà‡∏≤)
        combined_text = df.astype(str).agg(' '.join, axis=1).str.lower()
        mask = combined_text.str.contains(q, na=False)
        res = df[mask]
        
        if not res.empty:
            found_results[title] = res

    # --- ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡πÅ‡∏ö‡∏ö‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡πà‡∏≠‡∏Å‡∏±‡∏ô ---
    if found_results:
        st.success(f"‚úÖ ‡πÄ‡∏à‡∏≠‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• `{search_val}` ‡πÉ‡∏ô {len(found_results)} ‡πÅ‡∏ó‡πá‡∏ö")
        for name, res_df in found_results.items():
            st.markdown(f"### üìÇ ‡πÅ‡∏ó‡πá‡∏ö: {name}")
            st.dataframe(res_df, use_container_width=True, hide_index=True)
            st.divider()
    else:
        st.error(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• `{search_val}`")
